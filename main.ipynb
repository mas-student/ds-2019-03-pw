{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pathlib\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from fonduer import Meta, init_logging\n",
    "from fonduer.candidates import CandidateExtractor\n",
    "from fonduer.candidates.models import candidate_subclass\n",
    "from fonduer.candidates.models import Mention\n",
    "from fonduer.candidates import MentionExtractor\n",
    "from fonduer.candidates import MentionNgrams\n",
    "from fonduer.utils.data_model_utils import get_row_ngrams\n",
    "from fonduer.candidates.matchers import LambdaFunctionMatcher, Intersect, Union\n",
    "from fonduer.candidates.models import mention_subclass\n",
    "from fonduer.parser.models import Document, Sentence\n",
    "from fonduer.parser.preprocessors import HTMLDocPreprocessor\n",
    "from fonduer.parser import Parser\n",
    "from pyparsing import Word, alphas\n",
    "from kanren import Relation, facts, var, run, eq\n",
    "from ipywidgets import interact, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-08 19:08:04,159][INFO] fonduer.meta:50 - Setting logging directory to: share/logs/2019-10-08_19-08-04\n",
      "[2019-10-08 19:08:04,198][INFO] fonduer.meta:134 - Connecting user:None to localhost:5432/ds_2019_03_pw\n",
      "[2019-10-08 19:08:04,349][INFO] fonduer.meta:161 - Initializing the storage schema\n"
     ]
    }
   ],
   "source": [
    "PARALLEL = 4\n",
    "\n",
    "DSN = os.environ.get('DSN')\n",
    "\n",
    "init_logging(log_dir=\"share/logs\")\n",
    "\n",
    "session = Meta.init(DSN).Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:23<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "NATIONALITY_LIMIT = 25\n",
    "\n",
    "def full_path(path): \n",
    "    return 'https://en.wikipedia.org/' + path.lstrip('/')\n",
    "\n",
    "def href(element): \n",
    "    return element.attrs['href']\n",
    "\n",
    "performer_list_soup = BeautifulSoup(requests.get('https://en.wikipedia.org/wiki/Category:Lists_of_musicians_by_nationality').text)\n",
    "performer_urls = [\n",
    "    full_path(href(a)) \n",
    "    for list_url in tqdm(performer_list_soup.select('div.mw-category div.mw-category-group ul li a')[:NATIONALITY_LIMIT])\n",
    "    for a in BeautifulSoup(requests.get(full_path(href(list_url))).text).select('div.columns ul li a')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERFORMER_LIMIT=17\n",
    "docs_path = pathlib.Path(\"data/perfomers/\")\n",
    "\n",
    "def save(url):\n",
    "    doc_path = docs_path / (url.split('/')[-1] + ' - Wikipedia.html')\n",
    "    if os.path.exists(doc_path):\n",
    "        return\n",
    "    print(f'save from {url}')\n",
    "    with open(doc_path, 'wt') as f:\n",
    "        f.write(requests.get(url).text)\n",
    "        \n",
    "for performer_url in performer_urls[:PERFORMER_LIMIT]:\n",
    "    save(performer_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 23\n",
      "Sentences: 17965\n"
     ]
    }
   ],
   "source": [
    "doc_preprocessor = HTMLDocPreprocessor(docs_path)\n",
    "\n",
    "doc_paths = [path for path in os.listdir(docs_path) if path.endswith('.html')]\n",
    "update = False\n",
    "# update = session.query(Document).count() < len(doc_paths)  # Расскомментировать для первичного заполнения\n",
    "if update:\n",
    "    print(f\"Some documents not found (only {session.query(Document).count()} from {len(doc_paths)}): initing...\")\n",
    "    corpus_parser = Parser(session, structural=True, lingual=True)\n",
    "    %time corpus_parser.apply(doc_preprocessor, parallelism=PARALLEL)\n",
    "\n",
    "print(f\"Documents: {session.query(Document).count()}\")\n",
    "print(f\"Sentences: {session.query(Sentence).count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = session.query(Document).order_by(Document.name).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Performer = mention_subclass(\"Performer\")\n",
    "Origin = mention_subclass(\"Origin\")\n",
    "Genre = mention_subclass(\"Genre\")\n",
    "Beginning = mention_subclass(\"Beginning\")\n",
    "Perfomance = mention_subclass(\"Perfomance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mention_span_matches_file_name(mention):\n",
    "    checked = mention.get_span()\n",
    "    if 'class=firstHeading' in mention.sentence.html_attrs and 'band' not in checked and not (set('()') & set(checked)):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "performer_name_matcher = LambdaFunctionMatcher(func=mention_span_matches_file_name)\n",
    "performer_name_matcher.longest_match_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_origin_table_row(mention):\n",
    "    if not mention.sentence.is_tabular():\n",
    "        return False\n",
    "    ngrams = get_row_ngrams(mention, lower=True)\n",
    "    origin_place_words = set([\"origin\"])\n",
    "    ngrams = list(ngrams)\n",
    "    if origin_place_words <= set(ngrams):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def origin_left_aligned_to_punctuation(mention):\n",
    "    for sentence in mention.sentence.cell.sentences:\n",
    "        sentence_parts = sentence.text.split(\",\")\n",
    "        for sentence_part in sentence_parts:\n",
    "            if sentence_part.startswith(mention.get_span()):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def no_commas_in_origin(mention):\n",
    "    if \",\" in mention.get_span():\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_in_labeled_row_matcher = LambdaFunctionMatcher(\n",
    "    func=is_in_origin_table_row\n",
    ")\n",
    "origin_in_labeled_row_matcher.longest_match_only = False\n",
    "origin_no_commas_matcher = LambdaFunctionMatcher(func=no_commas_in_origin)\n",
    "origin_left_aligned_matcher = LambdaFunctionMatcher(\n",
    "    func=origin_left_aligned_to_punctuation\n",
    ")\n",
    "\n",
    "origin_matcher = Intersect(\n",
    "    origin_in_labeled_row_matcher,\n",
    "    origin_no_commas_matcher,\n",
    "    origin_left_aligned_matcher,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_genre_table_row(mention):\n",
    "    if not mention.sentence.is_tabular():\n",
    "        return False\n",
    "    ngrams = get_row_ngrams(mention, lower=True)\n",
    "    origin_place_words = set([\"genres\"])\n",
    "    ngrams = list(ngrams)\n",
    "    if origin_place_words <= set(ngrams):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "genre_in_labeled_row_matcher = LambdaFunctionMatcher(\n",
    "    func=is_in_genre_table_row\n",
    ")\n",
    "genre_in_labeled_row_matcher.longest_match_only = True\n",
    "\n",
    "genre_matcher = Intersect(\n",
    "    genre_in_labeled_row_matcher,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_years_active_table_row(mention):\n",
    "    if not mention.sentence.is_tabular():\n",
    "        return False\n",
    "    ngrams = get_row_ngrams(mention, lower=True)\n",
    "    origin_place_words = set(['years', 'active'])\n",
    "    ngrams = list(ngrams)\n",
    "    if origin_place_words <= set(ngrams) and mention.get_span() == mention.sentence.text.split('-')[0]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "beginning_in_labeled_row_matcher = LambdaFunctionMatcher(\n",
    "    func=is_in_years_active_table_row\n",
    ")\n",
    "beginning_in_labeled_row_matcher.longest_match_only = True\n",
    "\n",
    "beginning_matcher = Intersect(\n",
    "    beginning_in_labeled_row_matcher,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_in_title_column(mention):\n",
    "    if mention.sentence.cell:\n",
    "        cell = mention.sentence.cell\n",
    "        header = ''.join(sentence.text for sentence in cell.table.cells[cell.col_start].sentences)\n",
    "        if 'title' in header.lower():\n",
    "            return True\n",
    "\n",
    "def mention_fill_whole_cell(mention):\n",
    "    maybe = mention.get_span()\n",
    "    if mention.sentence.cell:\n",
    "        cell_text = ''.join(sentence.text for sentence in mention.sentence.cell.sentences)\n",
    "        if cell_text.lower() == maybe.lower():\n",
    "            return True\n",
    "\n",
    "performance_cell_in_title_column = LambdaFunctionMatcher(func=cell_in_title_column)\n",
    "performance_mention_fill_whole_cell = LambdaFunctionMatcher(func=mention_fill_whole_cell)\n",
    "\n",
    "performance_matcher = Intersect(\n",
    "    performance_cell_in_title_column,\n",
    "    performance_mention_fill_whole_cell,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "performer_name_ngrams = MentionNgrams(n_max=4, n_min=1)\n",
    "origin_ngrams = MentionNgrams(n_max=3)\n",
    "genre_ngrams = MentionNgrams(n_max=2)\n",
    "beginning_ngrams = MentionNgrams(n_max=2, split_tokens=['-'])\n",
    "performance_ngrams = MentionNgrams(n_min=1, n_max=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mention_extractor = MentionExtractor(\n",
    "    session,\n",
    "    [Performer, Origin, Genre, Beginning, Perfomance],\n",
    "    [performer_name_ngrams, origin_ngrams, genre_ngrams, beginning_ngrams, performance_ngrams],\n",
    "    [performer_name_matcher, origin_matcher, genre_matcher, beginning_matcher, performance_matcher],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-08 19:08:32,828][INFO] fonduer.candidates.mentions:459 - Clearing table: performer\n",
      "[2019-10-08 19:08:32,928][INFO] fonduer.candidates.mentions:459 - Clearing table: origin\n",
      "[2019-10-08 19:08:32,974][INFO] fonduer.candidates.mentions:459 - Clearing table: genre\n",
      "[2019-10-08 19:08:33,088][INFO] fonduer.candidates.mentions:459 - Clearing table: beginning\n",
      "[2019-10-08 19:08:33,141][INFO] fonduer.candidates.mentions:459 - Clearing table: perfomance\n",
      "[2019-10-08 19:08:33,187][INFO] fonduer.utils.udf:54 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270d813d376e43779e7012dcd5ec922d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Mentions: 372 ( 24 names 37 origins 244 genres 18 beginning 31 perfomance)\n"
     ]
    }
   ],
   "source": [
    "mention_extractor.apply(docs, parallelism=PARALLEL)\n",
    "num_names = session.query(Performer).count()\n",
    "num_origins = session.query(Origin).count()\n",
    "num_genres = session.query(Genre).count()\n",
    "num_beginnings = session.query(Beginning).count()\n",
    "num_perfomances = session.query(Perfomance).count()\n",
    "\n",
    "print(\n",
    "    f'Total Mentions: {session.query(Mention).count()} ('\n",
    "    f' {num_names} names'\n",
    "    f' {num_origins} origins'\n",
    "    f' {num_genres} genres'\n",
    "    f' {num_beginnings} beginning'\n",
    "    f' {num_perfomances} perfomance'\n",
    "    f')'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2019-10-08 19:08:52,523][INFO] fonduer.candidates.candidates:125 - Clearing table performer_origin (split 0)\n",
      "[2019-10-08 19:08:52,704][INFO] fonduer.candidates.candidates:125 - Clearing table performer_genre (split 0)\n",
      "[2019-10-08 19:08:52,814][INFO] fonduer.candidates.candidates:125 - Clearing table performer_beginning (split 0)\n",
      "[2019-10-08 19:08:52,870][INFO] fonduer.candidates.candidates:125 - Clearing table performer_perfomance (split 0)\n",
      "[2019-10-08 19:08:52,901][INFO] fonduer.candidates.candidates:125 - Clearing table performer_and_all_all_all (split 0)\n",
      "[2019-10-08 19:08:52,980][INFO] fonduer.utils.udf:54 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdb17320a694abe9de537ec334f2b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Candidates: 335\n"
     ]
    }
   ],
   "source": [
    "PerformerOrigin = candidate_subclass(\n",
    "    \"PerformerOrigin\", [Performer, Origin]\n",
    ")\n",
    "\n",
    "PerformerGenre = candidate_subclass(\n",
    "    \"PerformerGenre\", [Performer, Genre]\n",
    ")\n",
    "\n",
    "PerformerBeginning = candidate_subclass(\n",
    "    \"PerformerBeginning\", [Performer, Beginning]\n",
    ")\n",
    "\n",
    "PerformerPerfomance = candidate_subclass(\n",
    "    \"PerformerPerfomance\", [Performer, Perfomance]\n",
    ")\n",
    "\n",
    "PerformerAndAllAllAll = candidate_subclass(\n",
    "    \"PerformerAndAllAllAll\", [Performer, Origin, Genre, Beginning, Perfomance]\n",
    ")\n",
    "\n",
    "candidate_extractor = CandidateExtractor(session, [\n",
    "    PerformerOrigin, PerformerGenre, PerformerBeginning, PerformerPerfomance, PerformerAndAllAllAll\n",
    "])\n",
    "candidate_extractor.apply(docs, split=0, parallelism=PARALLEL)\n",
    "\n",
    "print(\n",
    "    f\"Number of Candidates: {session.query(PerformerAndAllAllAll).count()}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = Relation()\n",
    "genre = Relation()\n",
    "beginning = Relation()\n",
    "perfomance = Relation()\n",
    "\n",
    "facts(origin,\n",
    "    *[\n",
    "        (\n",
    "            cand_origin.origin.context.get_span().lower(), \n",
    "            cand_origin.performer.context.get_span().lower()\n",
    "        )\n",
    "        for cand_origin in session.query(PerformerOrigin)\n",
    "])\n",
    "\n",
    "\n",
    "facts(genre,\n",
    "    *[\n",
    "        (\n",
    "            cand_genre.genre.context.get_span().lower(), \n",
    "            cand_genre.performer.context.get_span().lower()\n",
    "        )\n",
    "        for cand_genre in session.query(PerformerGenre)\n",
    "])\n",
    "\n",
    "facts(beginning,\n",
    "    *[\n",
    "        (\n",
    "            cand_beginning.beginning.context.get_span().lower(), \n",
    "            cand_beginning.performer.context.get_span().lower()\n",
    "        )\n",
    "        for cand_beginning in session.query(PerformerBeginning)\n",
    "])\n",
    "\n",
    "facts(perfomance,\n",
    "    *[\n",
    "        (\n",
    "            cand_perfomance.perfomance.context.get_span().lower(), \n",
    "            cand_perfomance.performer.context.get_span().lower()\n",
    "        )\n",
    "        for cand_perfomance in session.query(PerformerPerfomance)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027986fc8a604234bf1385fadae42b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='Where from \"blutengel\"', description='question'), Output()), _dom_classes=('…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LIMIT = 7\n",
    "\n",
    "sample = 'Where from \"blutengel\"'\n",
    "\n",
    "@interact\n",
    "def answer(question=sample):\n",
    "    from pyparsing import Combine, OneOrMore, White, printables\n",
    "    object_var = Word(alphas).setResultsName('object')\n",
    "    subject_var = ('\"' + OneOrMore(Word(alphas)) + '\"').setResultsName('subject')\n",
    "    templates = {\n",
    "        None: [\n",
    "            'What' + ' ' + 'is' + object_var + 'for' + subject_var + \"?\",\n",
    "        ],\n",
    "        'origin': [\n",
    "            'Where from' + subject_var,\n",
    "        ],\n",
    "        'genre': [\n",
    "            'Who does' + subject_var + 'belong' + 'to',\n",
    "        ],\n",
    "        'beginning': [\n",
    "            'When was' + subject_var + 'created'+ 'at' + '?',\n",
    "        ],\n",
    "        'perfomance': [\n",
    "            'What does' + subject_var + 'execute?',\n",
    "        ],\n",
    "        'similiar': [\n",
    "            'What is' + subject_var + 'similiar' + 'to' + '?',\n",
    "            'What similiar' + subject_var ,\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    result = None\n",
    "    subject_name = None\n",
    "    object_name = None\n",
    "\n",
    "    for obj_name, object_templates in templates.items():\n",
    "        if object_name:\n",
    "            break\n",
    "        for template in object_templates:\n",
    "            if object_name:\n",
    "                break\n",
    "            try:\n",
    "                res = template.parseString(question)\n",
    "\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "            else:\n",
    "                subject_name = ' '.join(res['subject']).strip('\" ').lower() # res['subject'].lower()\n",
    "                \n",
    "                if obj_name is not None:\n",
    "                    object_name = obj_name\n",
    "                else:\n",
    "                    object_name = res['object']\n",
    "                \n",
    "    if object_name is None:\n",
    "        print(f'Incorrect question ({question}). Input correct question')\n",
    "        return\n",
    "    \n",
    "    performers = [\n",
    "        performer.context.get_span().lower()\n",
    "        for performer\n",
    "        in session.query(Performer)\n",
    "    ]\n",
    "\n",
    "    if subject_name not in performers:\n",
    "        performers = ', '.join(sorted(performers))\n",
    "        print(f'Performer \"{subject_name}\" not found. Known performers are {performers}. Question {question}.')\n",
    "    \n",
    "    if object_name == 'origin':\n",
    "        x = var()\n",
    "        origin_name = (run(LIMIT, x, origin(x, f\"{subject_name}\"))+(None,))[0]\n",
    "        print(f'Performer {subject_name} originate from {origin_name}')\n",
    "        result = origin_name\n",
    "        \n",
    "    if object_name == 'genre':\n",
    "        x = var()\n",
    "        genre_names = run(LIMIT, x, genre(x, f\"{subject_name}\"))\n",
    "        print(f'Performer {subject_name} belongs to {\", \".join(genre_names)}')\n",
    "        result = genre_names\n",
    "\n",
    "    if object_name == 'beginning':\n",
    "        x = var()\n",
    "        beginning_date = (run(LIMIT, x, beginning(x, f\"{subject_name}\"))+(None,))[0]\n",
    "        print(f'Performer {subject_name} is created at {beginning_date}')\n",
    "        result = beginning_date\n",
    "\n",
    "    if object_name == 'perfomance':\n",
    "        x = var()\n",
    "        perfomance_names = run(LIMIT, x, perfomance(x, f\"{subject_name}\"))\n",
    "        print(f'Performer {subject_name} execute {\", \".join(perfomance_names)}')\n",
    "        result = perfomance_names\n",
    "\n",
    "    if object_name == 'similiar':\n",
    "        a = var()\n",
    "        b = var()\n",
    "        c = var()\n",
    "        similiar_names = set([\n",
    "             v2 \n",
    "             for v1, v2 \n",
    "             in run(77, (a, b), eq(a, subject_name), genre(c, a), genre(c, b)) if v1 != v2\n",
    "            ][:LIMIT])\n",
    "        print(f'Performer {subject_name} is similiar to {\", \".join((similiar_names))}')\n",
    "        result = similiar_names\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performer qntal is similiar to los fabulosos cadillacs, blutengel, heilung\n",
      "Performer qntal is created at 1991\n",
      "Performer qntal belongs to darkwave, industrial music, industrial, music, neofolk\n",
      "Performer qntal execute qntal ii, qntal i, nihil, qntal iv: ozymandias, qntal iii: tristan und isolde, qntal v: silver swan, illuminate\n"
     ]
    }
   ],
   "source": [
    "perfomers = [cand.performer.context.get_span().lower() for cand in list(session.query(PerformerAndAllAllAll))[:1]]\n",
    "\n",
    "assert len(perfomers) > 0\n",
    "\n",
    "performer = perfomers[0]\n",
    "\n",
    "assert answer(question=f'What is \"{performer}\" similiar to?') is not None\n",
    "assert answer(question=f'When was \"{performer}\" created at?') is not None\n",
    "assert answer(question=f'Who does \"{performer}\" belong to?') is not None\n",
    "assert answer(question=f'What does \"{performer}\" execute?') is not None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
